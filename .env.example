# Client-side access to the proxy (who can call /v1/chat/completions)
ALLOWED_API_KEYS=sk-demo1,sk-demo2

# Upstream vendor endpoint and credential
UPSTREAM_API_URL=https://fizzlycode.com/api/v1/messages?beta=true
UPSTREAM_API_KEY=cr_xxx

# Optional: tweak upstream headers (set to empty string to remove a header)
# UPSTREAM_ANTHROPIC_VERSION=2023-06-01
# UPSTREAM_ANTHROPIC_BETA=interleaved-thinking-2025-05-14,fine-grained-tool-streaming-2025-05-14
# UPSTREAM_ANTHROPIC_DANGEROUS=true
# UPSTREAM_USER_AGENT=claude-cli/2.0.25 (external, proxy)
# UPSTREAM_X_APP=cli

# Append/override/remove any upstream headers (JSON object)
# UPSTREAM_EXTRA_HEADERS_JSON={"vendor-header":"value","anthropic-beta":""}

# Model behavior
DEFAULT_MODEL=claude-3-5-sonnet-latest
# MODEL_ALIASES=claude-sonnet-4-5-20250929:claude-3-5-sonnet-latest
# Enforce a safe ceiling for `max_tokens` sent upstream (can raise if your upstream supports it)
MAX_TOKENS_HARD_LIMIT=16384

# Dynamic max_tokens (optional)
# Enable to auto-adjust max_tokens based on estimated prompt tokens and per-model context limit
# MAX_TOKENS_DYNAMIC=true
# Provide per-model context window (tokens) as JSON, e.g.: {"claude-3-5-sonnet-latest":200000}
# MODEL_CONTEXT_LIMITS_JSON={}
# TOKEN_EST_CHARS_PER_TOKEN=4.0
# DYNAMIC_SAFETY_MARGIN=1024
# IMAGE_TOKEN_EQUIV=256

# CORS origins (comma separated) or "*"
CORS_ORIGINS=*

# Proxy settings to reach upstream
# DEFAULT_PROXY_URL=http://127.0.0.1:7890
# UPSTREAM_PROXY_URL=

# Server port and gunicorn options
PORT=5000
GUNICORN_WORKERS=2
GUNICORN_TIMEOUT=300
